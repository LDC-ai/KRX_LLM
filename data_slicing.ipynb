{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "hftoken = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(hftoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "import random\n",
    "from litellm import completion, batch_completion\n",
    "import os\n",
    "import litellm\n",
    "\n",
    "# OpenAI API key 선언\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-xxx...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 데이터셋 로드\n",
    "ds = load_dataset('amphora/rewrite-se-quant')['train']\n",
    "\n",
    "# 전체 데이터셋을 미리 데이터프레임으로 변환\n",
    "df_ds = pd.DataFrame(ds)\n",
    "\n",
    "# 데이터프레임 초기화\n",
    "df = pd.DataFrame(columns=['query', 'question', 'response'])\n",
    "\n",
    "\n",
    "batch_size = 200\n",
    "total_length = len(ds['query'])\n",
    "\n",
    "# 반복문 안에서 현재 배치의 데이터프레임 생성 및 기존 데이터프레임에 추가\n",
    "for i in tqdm(range(0, total_length, batch_size), desc=\"Processing Batches\", unit=\"batch\"):\n",
    "    batch_end = min(i + batch_size, total_length)  # 끝 인덱스가 전체 길이를 넘지 않도록 설정\n",
    "\n",
    "    # 질문 생성용 prompt 포맷팅\n",
    "    batch_qrys = []\n",
    "    for t in df_ds['query'][i:batch_end]:\n",
    "        messages = [\n",
    "            {\"content\": \"Your job is creating quantitative finance questions in fluent Korean. You will be given a English QF question collected from the web. Restructure it to a test-like question, in formal Korean language. Return the question only.\", \"role\": \"system\"},\n",
    "            {\"content\": t, \"role\": \"user\"}\n",
    "        ]\n",
    "        batch_qrys.append(messages)\n",
    "\n",
    "    # 질문 생성\n",
    "    responses = batch_completion(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=batch_qrys,\n",
    "        # max_tokens=60\n",
    "    )\n",
    "\n",
    "    question_resps = []\n",
    "    for response in responses:\n",
    "        if isinstance(response, litellm.RateLimitError):\n",
    "            question_resps.append(\"Error: Rate limit exceeded or other issue\")\n",
    "        elif hasattr(response, 'choices') and len(response.choices) > 0:\n",
    "            question_resps.append(response.choices[0].message.content)\n",
    "        else:\n",
    "            question_resps.append(\"Error: Unexpected response format\")\n",
    "\n",
    "    # 질문 생성과 답변 생성 사이에 10초 간격 추가\n",
    "    print(i, '10초 대기')\n",
    "    time.sleep(10)\n",
    "    print('대기 종료')\n",
    "\n",
    "    # 답변 생성용 prompt 포맷팅\n",
    "    batch_qrys = []\n",
    "    for t in question_resps:\n",
    "        messages = [\n",
    "            {\"content\": \"You are a skilled financial expert in Korea. Make a response for the question. DO NOT introduce yourself.\", \"role\": \"system\"},\n",
    "            {\"content\": t, \"role\": \"user\"}\n",
    "        ]\n",
    "        batch_qrys.append(messages)\n",
    "\n",
    "    # 답변 생성\n",
    "    responses = batch_completion(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=batch_qrys,\n",
    "        # max_tokens=80\n",
    "    )\n",
    "\n",
    "    response_resps = []\n",
    "    for resp in responses:  # 'i' 대신 'resp'로 변수명 변경\n",
    "        if isinstance(resp, Exception):\n",
    "            print(f\"오류 발생: {str(resp)}\")\n",
    "        elif hasattr(resp, 'choices') and len(resp.choices) > 0:\n",
    "            response_resps.append(resp.choices[0].message.content)\n",
    "        else:\n",
    "            response_resps.append(\"Error: Unexpected response format\")\n",
    "\n",
    "\n",
    "    print(i, '5초 대기')\n",
    "    time.sleep(5)\n",
    "    print('대기 종료')\n",
    "\n",
    "    query_list = df_ds['query'].iloc[i:batch_end].tolist()\n",
    "\n",
    "    # 현재 배치의 데이터프레임 생성 및 기존 데이터프레임에 추가\n",
    "    batch_df = pd.DataFrame({\n",
    "        'query': query_list,\n",
    "        'question': question_resps,\n",
    "        'response': response_resps\n",
    "    })\n",
    "    df = pd.concat([df, batch_df], ignore_index=True)\n",
    "\n",
    "    print('total prompt tokens:', total_prompt_tokens_for_q + total_prompt_tokens_for_a)\n",
    "    print('prompt token costs:', round((total_prompt_tokens_for_q + total_prompt_tokens_for_a) / 1000000 * 0.150, 6))\n",
    "    print('total completion tokens:', total_completion_tokens_for_q + total_completion_tokens_for_a)\n",
    "    print('completion token costs:', round((total_completion_tokens_for_q + total_completion_tokens_for_a) / 1000000 * 0.600, 6))\n",
    "    print('total completion tokens_q:', total_completion_tokens_for_q)\n",
    "    print('total completion tokens_a:', total_completion_tokens_for_a)\n",
    "\n",
    "    # 원본 데이터셋의 query 길이\n",
    "    original_length = len(ds[\"query\"])\n",
    "\n",
    "    # 생성된 질문과 답변의 길이 확인\n",
    "    question_length = len(question_resps)\n",
    "    response_length = len(response_resps)\n",
    "\n",
    "    print(f\"Original length: {original_length}\")\n",
    "    print(f\"Generated question length: {question_length}\")\n",
    "    print(f\"Generated response length: {response_length}\")\n",
    "\n",
    "    # 길이가 다른지 확인\n",
    "    if question_length < original_length:\n",
    "        print(f\"Missing questions: {original_length - question_length}\")\n",
    "\n",
    "    if response_length < original_length:\n",
    "        print(f\"Missing responses: {original_length - response_length}\")\n",
    "\n",
    "    # 다음 배치를 처리하기 전 1분 간격 대기\n",
    "    print(i, '1분 대기')\n",
    "    time.sleep(60)\n",
    "    print('대기 종료')\n",
    "\n",
    "    \n",
    "\n",
    "# 최종 결과 확인\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"중복된 행의 개수: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문 생성 결과 길이 맞추기\n",
    "if len(question_resps) < len(ds[\"query\"]):\n",
    "    question_resps.extend([\"Error: Missing question\"] * (len(ds[\"query\"]) - len(question_resps)))\n",
    "\n",
    "# 답변 생성 결과 길이 맞추기\n",
    "if len(response_resps) < len(ds[\"query\"]):\n",
    "    response_resps.extend([\"Error: Missing response\"] * (len(ds[\"query\"]) - len(response_resps)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel 파일 저장\n",
    "# df.to_excel(\"output_path/result.xlsx\")\n",
    "\n",
    "# HuggingFace Hub 업로드 - token에 개인 HuggingFace 토큰을 입력해주시면 됩니다.\n",
    "result_df = Dataset.from_pandas(df)\n",
    "result_df.push_to_hub(\"LDC-ai/dataset\", token=hftoken)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
