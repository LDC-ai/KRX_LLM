{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "hftoken = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(hftoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.10.3: Fast Qwen2 patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: NVIDIA A100 80GB PCIe MIG 3g.40gb. Max memory: 39.5 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.1+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "max_seq_length = 2048\n",
    "dtype = None # None으로 지정할 경우 해당 컴퓨팅 유닛에 알맞은 dtype으로 저장됩니다. Tesla T4와 V100의 경우에는 Float16, Ampere+ 이상의 경우에는 Bfloat16으로 설정됩니다.\n",
    "load_in_4bit = True # 메모리 사용량을 줄이기 위해서는 4bit 양자화를 사용하실 것을 권장합니다.\n",
    "\n",
    "# 모델 및 토크나이저 선언\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen2-7B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # gated model을 사용할 경우 허깅페이스 토큰을 입력해주시길 바라겠습니다.\n",
    ")\n",
    "# LoRA Adapter 선언\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # 0을 넘는 숫자를 선택하세요. 8, 16, 32, 64, 128이 추천됩니다.\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",], # target module도 적절하게 조정할 수 있습니다.\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # 어떤 값이든 사용될 수 있지만, 0으로 최적화되어 있습니다.\n",
    "    bias = \"none\",    # 어떤 값이든 사용될 수 있지만, \"none\"으로 최적화되어 있습니다.\n",
    "    use_gradient_checkpointing = \"unsloth\", # 매우 긴 context에 대해 True 또는 \"unsloth\"를 사용하십시오.\n",
    "    random_state = 42,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None\n",
    ")\n",
    "prompt_format = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "아래는 지시사항과 추가 정보가 포함된 내용입니다. 주어진 내용을 참고하여 한국어로 적절하게 답변해 주세요.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51407ebc3a0a4c1f8bc2e71c83ea6ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/21950 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a678883e64345cdae23f4e8893da2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21950 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8fea312f6b43d79b43f005017f2e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating corpus split:   0%|          | 0/92 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43617f42994f476d8157fca64a017ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating queries split:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1390f10b7ea43f7bec74aae551ea08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/92 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['', 'question', 'response', 'formatted_text', '_id', 'title', 'text'],\n",
       "    num_rows: 22042\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def formatting_prompts_func1(examples):\n",
    "    instructions = examples[\"question\"]\n",
    "    outputs = examples[\"response\"]\n",
    "    texts = []\n",
    "    for instruction, output in zip(instructions, outputs):\n",
    "        text = prompt_format.format(instruction, output) + EOS_TOKEN # 마지막에 eos token을 추가해줌으로써 모델이 출력을 끝마칠 수 있게 만들어 줍니다.\n",
    "        texts.append(text)\n",
    "    return { \"formatted_text\" : texts, }\n",
    "pass\n",
    "\n",
    "def formatting_prompts_func2(examples):\n",
    "    instructions = examples[\"text\"]\n",
    "    outputs = examples[\"text\"]\n",
    "    texts = []\n",
    "    for instruction, output in zip(instructions, outputs):\n",
    "        text = prompt_format.format(instruction, output) + EOS_TOKEN # 마지막에 eos token을 추가해줌으로써 모델이 출력을 끝마칠 수 있게 만들어 줍니다.\n",
    "        texts.append(text)\n",
    "    return { \"formatted_text\" : texts, }\n",
    "pass\n",
    "\n",
    "dataset1 = load_dataset(\"LDC-ai/dataset\", split='train')\n",
    "dataset1 = dataset1.map(formatting_prompts_func1, batched = True,)\n",
    "\n",
    "dataset2 = load_dataset(\"Linq-AI-Research/FinanceRAG\",'FinQABench', split = \"corpus\")\n",
    "dataset2 = dataset2.map(formatting_prompts_func2, batched = True,)\n",
    "\n",
    "# dataset3 = load_dataset(\"BAAI/IndustryCorpus_finance\", split = \"train\")\n",
    "# dataset3 = dataset3.map(formatting_prompts_func2, batched = True,)\n",
    "\n",
    "# 데이터셋 통합\n",
    "combined_dataset = concatenate_datasets([dataset1, dataset2])\n",
    "\n",
    "combined_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n아래는 지시사항과 추가 정보가 포함된 내용입니다. 주어진 내용을 참고하여 한국어로 적절하게 답변해 주세요.\\n\\n### Instruction:\\n비배당 주식에 대한 미국형 콜 옵션의 가격을 정량적으로 계산하는 과정에 대해 설명하시오. 특히, 다음의 두 가지 식을 비교하면서 논의하시오. 유럽형 콜 옵션의 가격은 다음과 같이 주어집니다: \\n\\n\\n### Response:\\n비배당 주식에 대한 미국형 콜 옵션의 가격을 정량적으로 계산하려면 여러 방법이 있습니다. 그러나 일반적으로 가장 널리 사용되는 방법은 블랙-숄즈 모델(Black-Scholes Model)입니다. 그러나 미국형 옵션은 조기 행사 가능성이 있기 때문에 유럽형 옵션의 가격을 기반으로 하는 블랙-숄즈<|im_end|>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(combined_dataset)\n",
    "\n",
    "df['formatted_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n아래는 지시사항과 추가 정보가 포함된 내용입니다. 주어진 내용을 참고하여 한국어로 적절하게 답변해 주세요.\\n\\n### Instruction:\\n다음 문제를 읽고 정답으로 가장 알맞은 것을 고르시요.\\n### 질문: 다음 중 우리나라 주식시장 매매 제도에 대한 기술로 맞는 것은?\\n### 선택지: \\nA. 개장 시간은 오전 10시다.\\nB. 유가증권시장의 가격 제한폭은 전일 종가 대비 상하 15%이다.\\nC. 코스닥시장에는 가격 제한폭이 없다.\\nD. 점심시간(12~1시)에는 휴장한다.\\nE. 동시호가는 폐장 시간에만 적용한다.\\nF. K-OTC시장의 가격 제한폭은 전일 종가 대비 상하 30%이다.\\nG. K-OTC시장의 운영시간은 09:00부터 16:00까지이다.\\n\\n### Response:\\n본 질문의 정답을 찾기 위해 각 선택지들을 살펴봅니다.\\n\\nA. 개장 시간은 오전 10시다.\\n이 문장은 주식 시장의 개장 시간에 대한 정보이며, 일반적으로 주식 시장의 개장 시간은 이와 같으므로 올바른 정보라고 판단됩니다.\\n\\nB. 유가증권시장의 가격 제한폭은 전일 종가 대비 상하 15%이다.\\n이 문장은 주식 시장의 가격 제한폭에 대한 정보이며, 유가증권시장의 가격 제한폭이 전일 종가 대비 상하 15%라는 정보는 일반적으로 주식 시장의 규칙에 따른 정보라고 판단됩니다.\\n\\nC. 코스닥시장에는 가격 제한폭이 없다.\\n코스닥시장에 대한 정보입니다. 실제로 코스닥시장에는 가격 제한폭이 있으므로 이 문장은 잘못된 정보라고 판단됩니다.\\n\\nD. 점심시간(12~1시)에는 휴장한다.\\n이 문장은 주식 시장의 휴장 시간에 대한 정보이며, 대부분의 주식 시장에서 점심시간에는 휴장하지 않는다는 정보가 일반적입니다. 따라서 이 문장은 잘못된 정보라고 판단됩니다.\\n\\nE. 동시호가는 폐장 시간에만 적용한다.\\n이 문장은 주식 시장의 동시호가 제한에 대한 정보입니다. 동시호가 제한은 주로 폐장 시간에 적용되는 것으로 알려져 있으므로 이 문장은 올바른 정보라고 판단됩니다.\\n\\nF. K-OTC시장의 가격 제한폭은 전일 종가 대비 상하 30%이다.\\n이 문장은 주식 시장의 가격 제한폭에 대한 정보이며, K-OTC시장의 가격 제한폭이 전일 종가 대비 상하 30%라는 정보는 일반적으로 주식 시장의 규칙에 따른 정보라고 판단됩니다.\\n\\nG. K-OTC시장의 운영시간은 09:00부터 16:00까지이다.\\n이 문장은 주식 시장의 운영시간에 대한 정보이며, K-OTC시장의 운영시간이 09:10부터 16:10까지라는 정보는 일반적으로 주식 시장의 규칙에 따른 정보라고 판단됩니다.\\n\\n따라서, 가장 알맞은 정답을 고르면 A, B, E, F, G가 해당될 수 있습니다. 이들 중에서 가장 명확한 정답을 고르면 A와 E가 가장 명확한 정답으로 보입니다. 그러나 주어진 질문에 대한 정확한 답을 제공하기 위해서는 추가 정보나 구체적인 맥락이 필요합니다. 이 질문의 경우, 여러 가지 정보들이 혼합되어 있으며, 어느 한 가지 선택지가 모든 정보를 반영하는 것은 아닙니다. 따라서 이 질문에 대한 가장 정확한 답변을 제공하기 위해서는 추가 정보나 구체적인 맥락이 필요합니다.<|im_end|>']\n",
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "아래는 지시사항과 추가 정보가 포함된 내용입니다. 주어진 내용을 참고하여 한국어로 적절하게 답변해 주세요.\n",
      "\n",
      "### Instruction:\n",
      "다음 문제를 읽고 정답으로 가장 알맞은 것을 고르시요.\n",
      "### 질문: 다음 중 우리나라 주식시장 매매 제도에 대한 기술로 맞는 것은?\n",
      "### 선택지: \n",
      "A. 개장 시간은 오전 10시다.\n",
      "B. 유가증권시장의 가격 제한폭은 전일 종가 대비 상하 15%이다.\n",
      "C. 코스닥시장에는 가격 제한폭이 없다.\n",
      "D. 점심시간(12~1시)에는 휴장한다.\n",
      "E. 동시호가는 폐장 시간에만 적용한다.\n",
      "F. K-OTC시장의 가격 제한폭은 전일 종가 대비 상하 30%이다.\n",
      "G. K-OTC시장의 운영시간은 09:00부터 16:00까지이다.\n",
      "\n",
      "### Response:\n",
      "본 질문의 정답을 찾기 위해 각 선택지들을 살펴봅니다.\n",
      "\n",
      "A. 개장 시간은 오전 10시다.\n",
      "이 문장은 주식 시장의 개장 시간에 대한 정보이며, 일반적으로 주식 시장의 개장 시간은 이와 같으므로 올바른 정보라고 판단됩니다.\n",
      "\n",
      "B. 유가증권시장의 가격 제한폭은 전일 종가 대비 상하 15%이다.\n",
      "이 문장은 주식 시장의 가격 제한폭에 대한 정보이며, 유가증권시장의 가격 제한폭이 전일 종가 대비 상하 15%라는 정보는 일반적으로 주식 시장의 규칙에 따른 정보라고 판단됩니다.\n",
      "\n",
      "C. 코스닥시장에는 가격 제한폭이 없다.\n",
      "코스닥시장에 대한 정보입니다. 실제로 코스닥시장에는 가격 제한폭이 있으므로 이 문장은 잘못된 정보라고 판단됩니다.\n",
      "\n",
      "D. 점심시간(12~1시)에는 휴장한다.\n",
      "이 문장은 주식 시장의 휴장 시간에 대한 정보이며, 대부분의 주식 시장에서 점심시간에는 휴장하지 않는다는 정보가 일반적입니다. 따라서 이 문장은 잘못된 정보라고 판단됩니다.\n",
      "\n",
      "E. 동시호가는 폐장 시간에만 적용한다.\n",
      "이 문장은 주식 시장의 동시호가 제한에 대한 정보입니다. 동시호가 제한은 주로 폐장 시간에 적용되는 것으로 알려져 있으므로 이 문장은 올바른 정보라고 판단됩니다.\n",
      "\n",
      "F. K-OTC시장의 가격 제한폭은 전일 종가 대비 상하 30%이다.\n",
      "이 문장은 주식 시장의 가격 제한폭에 대한 정보이며, K-OTC시장의 가격 제한폭이 전일 종가 대비 상하 30%라는 정보는 일반적으로 주식 시장의 규칙에 따른 정보라고 판단됩니다.\n",
      "\n",
      "G. K-OTC시장의 운영시간은 09:00부터 16:00까지이다.\n",
      "이 문장은 주식 시장의 운영시간에 대한 정보이며, K-OTC시장의 운영시간이 09:10부터 16:10까지라는 정보는 일반적으로 주식 시장의 규칙에 따른 정보라고 판단됩니다.\n",
      "\n",
      "따라서, 가장 알맞은 정답을 고르면 A, B, E, F, G가 해당될 수 있습니다. 이들 중에서 가장 명확한 정답을 고르면 A와 E가 가장 명확한 정답으로 보입니다. 그러나 주어진 질문에 대한 정확한 답을 제공하기 위해서는 추가 정보나 구체적인 맥락이 필요합니다. 이 질문의 경우, 여러 가지 정보들이 혼합되어 있으며, 어느 한 가지 선택지가 모든 정보를 반영하는 것은 아닙니다. 따라서 이 질문에 대한 가장 정확한 답변을 제공하기 위해서는 추가 정보나 구체적인 맥락이 필요합니다.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"formatted_text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # True로 설정하면 짧은 텍스트 데이터에 대해서는 더 빠른 학습 속도로를 보여줍니다.\n",
    "    args = TrainingArguments( # TrainingArguments는 자신의 학습 환경과 기호에 따라 적절하게 설정하면 됩니다.\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        # num_train_epochs = 1,\n",
    "        max_steps = 60,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 42,\n",
    "        output_dir = \"outputs\",\n",
    "    ),\n",
    ")\n",
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    prompt_format.format(\n",
    "        \"\"\"다음 문제를 읽고 정답으로 가장 알맞은 것을 고르시요.\n",
    "### 질문: 다음 중 우리나라 주식시장 매매 제도에 대한 기술로 맞는 것은?\n",
    "### 선택지: \n",
    "A. 개장 시간은 오전 10시다.\n",
    "B. 유가증권시장의 가격 제한폭은 전일 종가 대비 상하 15%이다.\n",
    "C. 코스닥시장에는 가격 제한폭이 없다.\n",
    "D. 점심시간(12~1시)에는 휴장한다.\n",
    "E. 동시호가는 폐장 시간에만 적용한다.\n",
    "F. K-OTC시장의 가격 제한폭은 전일 종가 대비 상하 30%이다.\n",
    "G. K-OTC시장의 운영시간은 09:00부터 16:00까지이다.\"\"\", # instruction\n",
    "        \"\", # output 생성을 위해 빈 칸으로 설정\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 1024, use_cache = True)\n",
    "print(tokenizer.batch_decode(outputs))\n",
    "for item in tokenizer.batch_decode(outputs):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 29.99 out of 48.0 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 29.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: You are pushing to hub, but you passed your HF username = LDC-ai.\n",
      "We shall truncate LDC-ai/test_model to test_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 29.94 out of 48.0 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 34.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f672401570b4be08c4e1e2aa3648ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/587 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d893885a4ede4e95bba4aa5af91ea181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3ba6e9257747e997edd5576b70aef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86b7b369c80419688d924635e49e859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1a3a73791f4c28a70f5813c32aa09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e54a530e4d4d13a3547f657d5a6a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Saved merged model to https://huggingface.co/LDC-ai/test_model\n"
     ]
    }
   ],
   "source": [
    "# # LoRA Adapter 저장\n",
    "# model.save_pretrained(\"lora_model\")\n",
    "# tokenizer.save_pretrained(\"lora_model\")\n",
    "\n",
    "# # Merged model 저장 및 업로드\n",
    "# model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
    "model.push_to_hub_merged(\"LDC-ai/test_model\", tokenizer, save_method = \"merged_16bit\", token = hftoken) # 개인 huggingface token을 사용하여 업로드할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
